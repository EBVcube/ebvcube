---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  error=TRUE 
)
```

# ebvcube package

<!-- badges: start -->
<!-- badges: end -->

This package can be used to easily access the data of the EBV netCDFs which can be downloaded from the
[EBV Data Portal](https://portal.geobon.org/). It also provides some basic visualization. Advanced users can build their own netCDFs following the EBV structure.

## 1. Basis
The EBV netCDF structure is designed to hold Essential Biodiversity Variables. This concept is further described [here](https://geobon.org/ebvs/what-are-ebvs/).
The files are based on the [Network Common Data Format](https://www.unidata.ucar.edu/software/netcdf/) (netCDF). Additionally, it follows the [Climate and Forecast Conventions](https://cfconventions.org/Data/cf-conventions/cf-conventions-1.8/cf-conventions.html) (CF, version 1.8) and the [Attribute Convention for Data Discovery](https://wiki.esipfed.org/Attribute_Convention_for_Data_Discovery_1-3) (ACDD, version 1.3).

## 2. Data structure
The structure allows several datacubes per netCDF file. These cubes have four dimensions: longitude, latitude, time and entity, whereby the last dimension can, e.g., encompass different species or groups of species, ecosystem types or other. The usage of hierarchical groups enables the coexistence of multiple EBV cubes.
The first level (netCDF group) are scenarios, e.g., the modelling for different Shared Socioeconomic Pathways (SSP) scenarios. The second level (netCDF group) are metrics, e.g., the percentage of protected area per pixel and its proportional loss over a certain time span per pixel. All metrics are repeated per scenario, if any are present.

```bash
├── scenario_1
│   └── metric_1
│       └── ebv_cube
└── scenario_2
    └── metric_2
        └── ebv_cube
```

Just keep in mind: All EBV netCDF always have a metric. But they may or may not have a scenario. The resulting datacubes hold the data. These datacubes are 4D.

## 2. Installation

You can install the ebvcube packages with: 

``` r
devtools::install_github('https://github.com/LuiseQuoss/ebvcube')

```
This packages uses GDAL tools (GDAL version: 3.1.4). You need a GDAL installation on your machine. 
One possibility to install GDAL is the [OSGeo4W Network installer](https://trac.osgeo.org/osgeo4w/). Check GDAL when running the installation! If you have QGIS on your machine, GDAL should be included.
If you have problems you can set the GDAL related paths by hand using the following lines of code. Your paths will differ! First check your GDAL installation.
```{r, eval=F, echo=T}
#add GDAL path to the existing paths
Sys.setenv(PATH = paste0('C:\\OSGeo4W64\\bin;',Sys.getenv("PATH")))
#check and change path for proj_lib, gdal_data and gdal_driver_path
Sys.setenv(PROJ_LIB = 'C:\\OSGeo4W64\\share\\proj')
Sys.setenv(GDAL_DATA = 'C:\\OSGeo4W64\\share\\gdal')
Sys.setenv(GDAL_DRIVER_PATH = 'C:\\OSGeo4W64\\bin\\gdalplugins')

#you can always check your GDAL path settings using
Sys.getenv("PATH")
Sys.getenv("PROJ_LIB") 
Sys.getenv("GDAL_DATA") 
Sys.getenv("GDAL_DRIVER_PATH") 

```


## 3. Working with the package - a quick intro

### 3.1 Take a very first look at the file

With the following two functions you get the core information about the data of a specific EBV netCDF.
First we take a look at some basic metadata of that file. The properties encompass much more information!

```{r example}
library(ebvcube)

#set the path to the file
file <- system.file(file.path("extdata","martins_comcom_id1_20220208_v1.nc"), package="ebvcube")

#read the properties of the file
prop.file <- ebv_properties(file)

#take a look at the general properties of the dataset - there are more properties to discover!
prop.file@general
slotNames(prop.file)


```

Now let's get the paths to all possible datacubes. The resulting dataframe includes the paths and also descriptions of the metric and/or scenario and/or entity. The paths basically consist of the nested structure of scenario, metric and the datacube.

```{r}
datacubes <- ebv_datacubepaths(file)
datacubes
```

In the next step we will get the properties of one specific datacube - fyi: the result also holds the general file properties from above.

```{r}
prop.dc <- ebv_properties(file, datacubes[1,1])
prop.dc@ebv_cube
```


### 3.2 Plot the data to get a better impression
To discover the spatial distribution of the data, you can plot a map of the datacube that we just looked at. It has 12 timesteps. Here we look at the sixth one.

```{r}
#plot the global map
dc <- datacubes[1,1]
ebv_map(file, dc, entity=1, timestep = 1)

# What was the data about again? Check the properties!
prop.dc@general$title
# And the datacube?
prop.dc@ebv_cube$standard_name
#What time is the sixth timestep representing?
prop.dc@temporal$timesteps_natural[6]

```

It's nice to see the global distribution, but how is the change of that datacube (non forest birds) over time? Let's take a look at the average. The function returns the values, catch them!

```{r}
#get the averages and plot
averages <- ebv_trend(file, dc, entity=1)
averages
```

It would be cool to have that for other indicators as well? Check out the different options for 'method'.

### 3.3 Read the data from the files to start working
Before you actually load the data it may be nice to get an impression of the value range and other basic measurements. 

```{r}
#info for whole dataset
measurements <- ebv_analyse(file, dc, entity=1)
#see the included measurements
names(measurements)
#how many pixels are included?
measurements$n
measurements$mean

#info for a subset defined by a bounding box (roughly(!) Germany)
bb <- c(5,15,47,55)
measurements.bb <- ebv_analyse(file, dc, entity = 1, subset = bb)
#how many pixels are now included?
measurements.bb$n
measurements.bb$mean
```

To access the data you can use the following: 
```{r}
#load whole data as array for two timesteps
data <- ebv_read(file, dc, entity = 1, timestep = c(1,2), type = 'a')
dim(data)
```
To subset the data using a shapefile you need to indicate a directory for temporarily created files.
```{r}
#load subset from shapefile (Germany)
shp <- system.file(file.path('extdata','subset_germany.shp'), package="ebvcube")
#define directory for temporary files
options('ebv_temp'=system.file("extdata/", package="ebvcube"))
data.shp <- ebv_read_shp(file, dc, entity=1, shp = shp, timestep = c(1,2,3))
dim(data.shp)
#very quick plot of the resulting raster plus the shapefile
borders <- terra::vect(shp)
ggplot2::ggplot() +
  tidyterra::geom_spatraster(data = data.shp[[1]]) +
  tidyterra::geom_spatvector(data = borders, fill = NA) +
  ggplot2::scale_fill_fermenter(na.value=NA, palette = 'YlGn', direction = 1) +
  ggplot2::theme_classic()
  
```
Imagine you have a very large dataset but only limited memory. The package provides the possibility to load the data as a DelayedArray. A second function helps you to write that data back on disk properly. Look into the manual to obtain more information.

### 3.4 Take a peek on the creation of an EBV netCDF
#### a. Create an empty EBV netCDF (with metadata)
First of all, you have to insert all the metadata in the [EBV Data Portal](https://portal.geobon.org/home) and then use the resulting text file (json format) to create an empty netCDF which complies to the EBV netCDF structure, i.e., it has the correct structure mapped to your data and holds the metadata. Additionally to that (json) text file the function needs a list of all entities the netCDF (csv list, see help page for detailed information) will encompass and geospatial information such as the coordinate reference system.

The example is based on the [Local bird diversity (cSAR/BES-SIM) ](https://portal.geobon.org/ebv-detail?id=1). 

```{r}
#paths
json <- system.file(file.path('extdata','metadata.json'), package="ebvcube")
newNc <- file.path(system.file(package="ebvcube"),'extdata','test.nc')
entities <- file.path(system.file(package='ebvcube'),"extdata","entities.csv")
#defining the fillvalue - optional
fv <- -3.4e+38
#create the netCDF
ebv_create(jsonpath = json, outputpath = newNc, entities = entities, 
           epsg = 4326, extent = c(-180, 180, -90, 90), resolution = c(1, 1),
           fillvalue = fv, prec='float', force_4D = TRUE, overwrite=T)

#needless to say: check the properties of your newly created file to see if you get what you want
#especially the entity_names from the slot general should be checked to see if your csv was formatted the right way
print(ebv_properties(newNc)@general[1])

#check out the (still empty) datacubes that are available
dc.new <- ebv_datacubepaths(newNc)
print(dc.new)
```
Hint: You can always take a look at your netCDF in [Panoply](https://www.giss.nasa.gov/tools/panoply/) provided by NASA. That's very helpful to understand the structure.

#### b. Add your data to the EBV NetCDF
In the next step you can add your data to the netCDF from GeoTiff files or in-memory objects (matrix/array). You need to indicate the datacubepath the data belongs to. You can add your data timestep per timestep, in slices or all at once. You can simply add more data to the same datacube by changing the timestep definition.

```{r}
#path to tif with data
root <- system.file(file.path('extdata'), package="ebvcube") 
tifs <- c('entity1.tif', 'entity2.tif', 'entity3.tif')
tif_paths <- file.path(root, tifs)
#adding the data
entity <- 1
for (tif in tif_paths){
  ebv_add_data(filepath_nc = newNc, datacubepath=dc.new[1,1], entity = entity,
              timestep=1:3, data = tif, band=1:3)
  entity <- entity + 1
}


```

#### c. Add missing attributes to datacube
Ups! So you did a mistake and want to change the attribute?! No problem. Just use the upcoming function to change it.
```{r}
ebv_attribute(newNc, attribute_name='units', value='percentage', levelpath=dc.new[1,1])
#check the properties one more time - perfect!
print(ebv_properties(newNc, dc.new[1,1])@ebv_cube$units)

```
In this case the levelpath corresponds to the datacube path. But you can also alter attributes at the metric or scenario level. See the manual for more info.

## 4. Cite package
```{r}
citation('ebvcube')
```


