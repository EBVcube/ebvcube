---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  error=TRUE 
)
```

# ebvnetcdf package

<!-- badges: start -->
<!-- badges: end -->

This package can be used to easily access the data of the EBV netCDFs which can be downloaded from the
[Geobon Portal](https://portal.geobon.org/). It also provides some basic visualization. Advanced users can build their own netCDFs with the EBV standard.

## 1. EBVs - Essential Biodiversity Variables
The EBV netCDF standard is designed to hold Essential Biodiversity Variables. This concept is further described [here](https://geobon.org/ebvs/what-are-ebvs/).
An important core element of the EBV netCDFs is their nested structure. All datacubes in the netCDF are assigned to one metric. But this metric can have several entities. On top of this hierarchy there can be several scenarios. The following block displays an abstract exhausted hierarchy.

```bash
├── scenario1
│   └── metric1
│       ├── entity1
│       ├── entity2
│       ├── ...
│       └── entity999
└── scenario2
    └── metric2
        ├── entity1
        ├── entity2
        ├── ...
        └── entity999
```

The following is a practical example of the netCDF structure. Basis is the [global habitat availability for mammals dataset](https://portal.geobon.org/ebv-detail?id=5).

```bash
├── SSP1-RCP2.6
│   └── absolute values per 5 years and species (km2)
│       ├── Hipposideros calcaratus
│       ├── Hipposideros fulvus
│       ├── ...
│       └── Habromys lepturus
│
├── SSP2-RCP4.5
│   └── absolute values per 5 years and species (km2)
│       ├── ...
│       └── Habromys lepturus
├── ...
│
└── SSP5-RCP8.5
    └── absolute values per 5 years and species (km2)
        ├── ...
        └── Habromys lepturus    

```

Just keep in mind: All EBV netCDF always have a metric. But they may or may not have a scenario and/or entity. The resulting datacubes are going to be accesses.

## 2. Installation

You can install the ebvnetcdf packages with: 

``` r
#currently:
# 1. pull git repo
# 2. open ebvnetcdf.RProj
# 3. install(devtools)
# 4. install(dependencies=T)

#future: when repo is public (Does not work right now.)
devtools::install_gitlab("lq39quba/ebvnetcdf", host='git.idiv.de')

```
This packages uses GDAL tools. You need a GDAL installation on your machine. 
GDAL version: 3.1.4

## 3. Working with the package - a quick intro

### 3.1 Take a very first look at the file

With the following two functions you get the core information about the data from a specific EBV netCDF.
First we take a look at some basic metadata of that file.

```{r example}
library(ebvnetcdf)

file <- system.file(file.path("extdata","cSAR_idiv_v1.nc"), package="ebvnetcdf")
prop.file <- ebv_properties(file)

#take a look at the general properties of the dataset - there are more properties to discover!
prop.file@general
slotNames(prop.file)


```

Now let's get the paths to all possible datacubes. The resulting dataframe includes the paths and also descriptions of the metric and/or scenario and/or entity.

```{r}
datacubes <- ebv_datacubepaths(file)
datacubes
```

In the next step we will get the properties of one specific datacube - fyi: the result also holds the general file properties from above.
This time you get the warning that the value_range does not exists. So don't take the displayed value_range seriously.

```{r}
prop.dc <- ebv_properties(file, datacubes[1,1], verbose=T)
prop.dc@entity
```


### 3.2 Plot the data to get a better impression
To discover the spatial distribution of the data you can plot a map of the datacube that we just looked at. It has 12 timesteps. Here we look at the sixth one.

```{r}
#plot the global map
dc <- datacubes[1,1]
ebv_map(file, dc, timestep = 6)

# What was the data about again? Check the properties!
prop.dc@general$title
# And the datacube?
prop.dc@entity$standard_name
#What time is the sixth timestep representing?
prop.dc@temporal$timesteps_natural[6]

```

It's nice to see the global distribution, but how is the change of that datacube (non forest birds) over time? Let's take a look at the average. The function returns the values, catch them!

```{r}
#get the averages and plot
averages <- ebv_indicator(file, dc)
averages
```

It would be cool to have that for other indicators as well? Well you have to wait for an update of the package. Or maybe implement it yourself using the functions coming up next?

### 3.3 Read the data from the files to start working
Before you actually load the data it may be nice to get an impression of the value range and other basic measurements. 

```{r}
#info for whole dataset
measurements <- ebv_analyse(file, dc)
#see the included measurements
names(measurements)
#how many pixels are included?
measurements$n
measurements$mean

#info for a subset defined by a bounding box (roughly(!) Germany)
bb <- c(5,15,47,55)
measurements.bb <- ebv_analyse(file, dc, bb)
#how many pixels are now included?
measurements.bb$n
measurements.bb$mean
```

To access the data you can use the following: 
```{r}
#load whole data as array for two timesteps
data <- ebv_read(file, dc, c(1,2), delayed = F)
dim(data)
```
To subset the data using a shapefile you need to indicate a directory for temporarily created files.
```{r}
#load subset from shapefile (Germany)
shp <- system.file(file.path('extdata','subset_germany.shp'), package="ebvnetcdf")
#define directory for temporary files
options('ebv_temp'=system.file("extdata/", package="ebvnetcdf"))
data.shp <- ebv_read_shp(file, dc, shp, NULL, c(1,2,3))
dim(data.shp)
#very quick plot of the resulting raster plus the shapefile
shp.data <- rgdal::readOGR(shp)
raster::spplot(data.shp[[1]], sp.layout = list(shp.data, first=FALSE))
```
Imagine you have a very large dataset but only limited memory. The package provides the possibility to load the data as a DelayedArray. A second function helps you to write that data back on disk properly. Look into the manual to obtain more information.

### 3.4 Take a peek on the creation of an EBV netCDF
#### a. Create an empty EBV netCDF (with metadata)
This process is still work in progress. Right now you'll have to insert all the metadata in the Geobon Portal and then use the resulting json file to create an empty netCDF file which complies to the EBV netCDF standard. It has the correct structure and holds the metadata. Additionally to that json file the function needs the amount of entities the netCDF will encompass and the coordinate reference system.

The example is based on the [Global habitat availability for mammals ](https://portal.geobon.org/ebv-detail?id=5). As its ID in the geoportal is 5 the json file is just called 5.

```{r}
#paths
json <- system.file(file.path('extdata','5.json'), package="ebvnetcdf")
newNc <- file.path(system.file(package="ebvnetcdf"),'extdata','mammals.nc')
#defining the fillvalue - optional
fv <- -3.4e+38
#lets say it has 5 entities, which is not true in reality!
ebv_create(json, newNc, 5, overwrite=T,fillvalue = fv, prec='float')
#check out the general propeties of our newly created file
print(ebv_properties(newNc)@general)
#check out the (still empty) datacubes
dc.new <- ebv_datacubepaths(newNc)
print(dc.new[c(1,5,6),])
```
Hint: You can always take a look at your netCDF in [Panoply](https://www.giss.nasa.gov/tools/panoply/) provided by NASA. That's very helpful to understand the structure.

#### b. Add your data to the EBV NetCDF
In the next step you can add your data to the netCDF from GeoTiff files. You need to indicate the datacubepath the data belongs to. You can add your data timestep per timestep, in slices or all at once. You can simply add more data to the same datacube by changing the timestep definition.

```{r}
#path to tif with data
tif <- system.file(file.path('extdata','mammals_ts123.tif'), package="ebvnetcdf") 
#adding the data
ebv_add_data(newNc, tif, datacubepath=dc.new[1,1], timestep=c(1,2,3), band=c(1,2,3))

```

#### c. Add missing attributes to datacube
Now there are still a information missing about the data you just added: the standard_name and description of each entity. The following function makes it possible to add the information.
Ups! So you did a mistake and want to change the attribute?! No problem. Just use the same function to change it again.
```{r}
ebv_attribute(newNc, attribute_name='standard_name', value='Eumops auripendulus', levelpath=dc.new[1,1])
#check the properties one more time - perfect!
print(ebv_properties(newNc, dc.new[1,1])@entity$standard_name)

```
In this case the levelpath corresponds to the datacube path. But you can also alter attributes at the metric or scenario level. See the manual for more info.

## 4. Cite package
```{r}
citation('ebvnetcdf')
```


